{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# There are three targets (labels) in the sample, which are labeled as 0(setosa), 1(versicolor), 2(virginica)  \n",
    "print(iris.target_names) \n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepallength  sepalwidth  petallength  petalwidth  species\n",
      "0           5.1         3.5          1.4         0.2        0\n",
      "1           4.9         3.0          1.4         0.2        0\n",
      "2           4.7         3.2          1.3         0.2        0\n",
      "3           4.6         3.1          1.5         0.2        0\n",
      "4           5.0         3.6          1.4         0.2        0\n",
      "5           5.4         3.9          1.7         0.4        0\n",
      "6           4.6         3.4          1.4         0.3        0\n",
      "7           5.0         3.4          1.5         0.2        0\n",
      "8           4.4         2.9          1.4         0.2        0\n",
      "9           4.9         3.1          1.5         0.1        0\n",
      "10          5.4         3.7          1.5         0.2        0\n",
      "11          4.8         3.4          1.6         0.2        0\n",
      "12          4.8         3.0          1.4         0.1        0\n",
      "13          4.3         3.0          1.1         0.1        0\n",
      "14          5.8         4.0          1.2         0.2        0\n",
      "15          5.7         4.4          1.5         0.4        0\n",
      "16          5.4         3.9          1.3         0.4        0\n",
      "17          5.1         3.5          1.4         0.3        0\n",
      "18          5.7         3.8          1.7         0.3        0\n",
      "19          5.1         3.8          1.5         0.3        0\n"
     ]
    }
   ],
   "source": [
    "# dividing the datasets into two parts i.e. training datasets and test datasets\n",
    "# X are samples and y are labels (targets)\n",
    "X, y = datasets.load_iris( return_X_y = True)\n",
    "\n",
    "# Splitting arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# i.e. 70 % training dataset and 30 % test datasets. When processing experimental data, we can use K-Fold division instead of \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
    "\n",
    "\n",
    "\n",
    "# This part is for data visualization, showing the data values from iris data set\n",
    "import pandas as pd \n",
    "data = pd.DataFrame({'sepallength': iris.data[:, 0], 'sepalwidth': iris.data[:, 1], \n",
    "\t\t\t\t\t'petallength': iris.data[:, 2], 'petalwidth': iris.data[:, 3], \n",
    "\t\t\t\t\t'species': iris.target}) \n",
    "print(data.head(20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY OF THE MODEL:  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "clf = RandomForestClassifier( n_estimators= 100)\n",
    "clf.fit (X_train, y_train)\n",
    "# performing predictions on the test dataset \n",
    "y_pred = clf.predict(X_test) \n",
    "# metrics are used to find accuracy or error \n",
    "from sklearn import metrics   \n",
    "print() \n",
    "# using metrics module for accuracy calculation \n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some examples to show the predictions of the model. One thing is that the the model cannot exclude bad examples with invalid paras\n",
    "clf.predict([[3, 3, 2, 2],\n",
    "             [3, 3, 1, 1],\n",
    "             [5, 4, 3, 2],\n",
    "             [3.4 , 5.5, 4.3, 7.9],\n",
    "             [0, 0, 0, 0],\n",
    "             [1e4, 1e4, 1e4, 1e4],\n",
    "             [-1, -1, -1, -1],\n",
    "             [-1e4, -1e4, -1e4, -1e4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal width (cm)     0.461855\n",
       "petal length (cm)    0.388065\n",
       "sepal length (cm)    0.110010\n",
       "sepal width (cm)     0.040070\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the feature importance \n",
    "feature_imp = pd.Series(clf.feature_importances_, index = iris.feature_names).sort_values(ascending = False) \n",
    "feature_imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
