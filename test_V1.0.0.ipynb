{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is a test for random forest classification, last edited in 2023/10/18 by Wan\n",
    "\n",
    "# importing necessary packages\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for training, only uses small amount of proton data\n",
    "datadir = 'D:/LHAASO_KM2A/LHAASO/Data/Simulation/Xishui/'\n",
    "npzfiles = glob.glob(datadir + 'rec.all.Proton.1.e16_1.e17.*.npz')\n",
    "for i, npzfile in enumerate(npzfiles):\n",
    "    if i==0:\n",
    "        test = np.load(npzfile, allow_pickle=True)\n",
    "        arr1 = test['E']\n",
    "        arr2 = test['NhitE']\n",
    "        arr3 = test['NhitM']\n",
    "        arr4 = arr2/arr3\n",
    "        arr5 = np.zeros(len(arr1))\n",
    "    else:\n",
    "        f = np.load(npzfile, allow_pickle=True)\n",
    "        ene = f['E']\n",
    "        ED = f['NhitE']\n",
    "        MD = f['NhitM']\n",
    "        EMr = ED/MD\n",
    "        lab1 = np.zeros(len(ene))\n",
    "        arr1 = np.append(arr1, ene)\n",
    "        arr2 = np.append(arr2,ED)\n",
    "        arr3 = np.append(arr3,MD)\n",
    "        arr4 = np.append(arr4, EMr)\n",
    "        arr5 = np.append(arr5, lab1)\n",
    "X_p = np.column_stack((arr1,arr2,arr3,arr4,arr5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for training, only uses small amount of Fe data\n",
    "datadir = 'D:/LHAASO_KM2A/LHAASO/Data/Simulation/Xishui/'\n",
    "npzfiles = glob.glob(datadir + 'rec.all.Fe.1.e16_1.e17.*.npz')\n",
    "for i, npzfile in enumerate(npzfiles):\n",
    "    if i==0:\n",
    "        test = np.load(npzfile, allow_pickle=True)\n",
    "        b1 = test['E']\n",
    "        b2 = test['NhitE']\n",
    "        b3 = test['NhitM']\n",
    "        b4 = b2/b3\n",
    "        b5 = 1 + np.zeros(len(b1))\n",
    "    else:\n",
    "        f = np.load(npzfile, allow_pickle=True)\n",
    "        eneb = f['E']\n",
    "        EDb = f['NhitE']\n",
    "        MDb = f['NhitM']\n",
    "        EMrb = EDb/MDb\n",
    "        lab1b = 1 + np.zeros(len(eneb))\n",
    "        b1 = np.append(b1, eneb)\n",
    "        b2 = np.append(b2,EDb)\n",
    "        b3 = np.append(b3,MDb)\n",
    "        b4 = np.append(b4, EMrb)\n",
    "        b5 = np.append(b5, lab1b)\n",
    "X_f = np.column_stack((b1,b2,b3,b4,b5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the final dataset for training, and shuffling is necessary. X_A is the total set of features and Y_A is the total set of labels\n",
    "X_A = np.row_stack((X_p, X_f))\n",
    "np.random.shuffle(X_A)\n",
    "Y_A= X_A[:,4:].flatten()\n",
    "X_A = X_A[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY OF THE MODEL:  0.7267161191569528\n"
     ]
    }
   ],
   "source": [
    "# Split the features and labels into a training set and a testing set, and then use random forest classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_A, Y_A, test_size = 0.30)\n",
    "clf = RandomForestClassifier( n_estimators= 100)\n",
    "clf.fit (X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print() \n",
    "# using metrics module for accuracy calculation  \n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.278687\n",
       "0    0.269693\n",
       "2    0.255964\n",
       "1    0.195656\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the feature importance \n",
    "feature_imp = pd.Series(clf.feature_importances_).sort_values(ascending = False) \n",
    "feature_imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
